{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting training data\n",
    "\n",
    "This notebook contains code to download metadata and transcripts for videos contained in training data (`Data/normalized_data/train.csv`) as well as in the encountered videos with metadata (`Data/normalized_data/videos_metadata.csv`) and to process them into a pandas DataFrame. The code here is based on the code provided by [Papadamou et al.](https://github.com/kostantinos-papadamou/pseudoscience-paper/tree/main/youtubehelpers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download videos' metadata and transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from socket import error as SocketError\n",
    "import time\n",
    "import glob\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUTUBE_API_SERVICE_NAME = 'youtube'\n",
    "YOUTUBE_API_VERSION = 'v3'\n",
    "YOUTUBE_API_KEY = 'YOUR_YOUTUBE_DATA_API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_api = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=YOUTUBE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_BASE_DIR = '../Data/raw_data/videos_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video_metadata(video_id):\n",
    "    while True:\n",
    "        try:\n",
    "            # Send request to get video's information\n",
    "            response = youtube_api.videos().list(\n",
    "                part='id,snippet,contentDetails,statistics',\n",
    "                id=video_id\n",
    "            ).execute()\n",
    "\n",
    "            # Get Video Details\n",
    "            try:\n",
    "                return response['items'][0]\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "        except (HttpError, SocketError) as error:\n",
    "            print(f'--- HTTP Error occurred while retrieving information for VideoID: {video_id}. [ERROR]: {error}')\n",
    "            time.sleep(30)\n",
    "\n",
    "\n",
    "def is_video_transcript_downloaded(video_id):\n",
    "    video_transcript = glob.glob(f'{VIDEO_BASE_DIR}/{video_id}/{video_id}_transcript.*')\n",
    "    if len(video_transcript) > 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def download_video_transcript(video_id):\n",
    "    video_url = f'https://www.youtube.com/watch?v={video_id}'\n",
    "    path = f'{VIDEO_BASE_DIR}/{video_id}/{video_id}_transcript'\n",
    "\n",
    "    try:\n",
    "        # download_video_transcript.sh needs to have execute permissions\n",
    "        output = subprocess.check_output(f'bash download_video_transcript.sh {video_url} {path}', shell=True)\n",
    "        if \"HTTP_ERROR\" in str(output):\n",
    "            print(output)\n",
    "            return\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        pass\n",
    "    return\n",
    "\n",
    "\n",
    "def download_video(video_id, download_transcript=True):\n",
    "    print('Downloading metadata...')\n",
    "    video_metadata = download_video_metadata(video_id)\n",
    "    \n",
    "    if video_metadata is None:\n",
    "        print(f'ERROR: Video Metadata not available for video: {video_id}')\n",
    "        return None\n",
    "\n",
    "    if download_transcript and not is_video_transcript_downloaded(video_id):\n",
    "        print('Downloading transcript...')\n",
    "        download_video_transcript(video_id)\n",
    "\n",
    "    return video_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = pd.read_csv('../Data/normalized_data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_ids = list(videos['youtube_id'])\n",
    "len(youtube_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(VIDEO_BASE_DIR):\n",
    "    os.mkdir(VIDEO_BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video_id in youtube_ids:\n",
    "    path = f'{VIDEO_BASE_DIR}/{video_id}/{video_id}.json'\n",
    "    if not os.path.exists(path):\n",
    "        print('Downloading video', video_id)\n",
    "        video_details = download_video(video_id)\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(video_details, f)\n",
    "        print('Done')\n",
    "        time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process downloaded train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train_video_metadata(path):\n",
    "    with open(path, 'r') as f:\n",
    "        video = json.load(f)\n",
    "\n",
    "        return {\n",
    "            'youtube_id': video['id'],\n",
    "            'published_at': video['snippet']['publishedAt'],\n",
    "            'updated_at': datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "            'view_count': video['statistics']['viewCount'] if 'viewCount' in video['statistics'] else np.nan,\n",
    "            'like_count': video['statistics']['likeCount'] if 'likeCount' in video['statistics'] else np.nan,\n",
    "            'dislike_count': video['statistics']['dislikeCount'] if 'dislikeCount' in video['statistics'] else np.nan,\n",
    "            'favourite_count': video['statistics']['favoriteCount'] if 'favoriteCount' in video['statistics'] else np.nan,\n",
    "            'comment_count': video['statistics']['commentCount'] if 'commentCount' in video['statistics'] else np.nan,\n",
    "            'duration': video['contentDetails']['duration']\n",
    "        }\n",
    "\n",
    "def get_video_transcript(path):\n",
    "    transcript_path = glob.glob(path)\n",
    "    if len(transcript_path) == 0:\n",
    "        return ''\n",
    "    \n",
    "    transcript_path = transcript_path[0]\n",
    "    with open(transcript_path, 'r') as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_videos = []\n",
    "\n",
    "for video_id in youtube_ids:\n",
    "    path = f'{VIDEO_BASE_DIR}/{video_id}/{video_id}.json'\n",
    "    transcript_path = f'{VIDEO_BASE_DIR}/{video_id}/{video_id}_transcript.*'\n",
    "    if os.path.exists(path):\n",
    "        processed_video = process_train_video_metadata(path)\n",
    "        processed_video['transcript'] = get_video_transcript(transcript_path)\n",
    "        processed_video['annotation'] = videos[videos['youtube_id'] == video_id]['annotation'].values[0]\n",
    "        \n",
    "        processed_train_videos.append(processed_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_videos_df = pd.DataFrame(processed_train_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_videos_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_videos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_videos_df.to_csv('../Data/normalized_data/train_processed.csv', index=False, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encountered data with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = pd.read_csv('../Data/normalized_data/videos_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_ids = list(videos['youtube_id'])\n",
    "len(youtube_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(VIDEO_BASE_DIR):\n",
    "    os.mkdir(VIDEO_BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video_id in youtube_ids:\n",
    "    path = f'{VIDEO_BASE_DIR}/{video_id}/{video_id}.json'\n",
    "    if not os.path.exists(path):\n",
    "        print('Downloading video', video_id)\n",
    "        video_details = download_video(video_id, download_transcript=False)\n",
    "        os.mkdir(os.path.join(VIDEO_BASE_DIR, video_id))\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(video_details, f)\n",
    "        print('Done')\n",
    "        time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process downloaded train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_encountered_video_metadata(path, videos_df):\n",
    "    with open(path, 'r') as f:\n",
    "        video = json.load(f)\n",
    "\n",
    "        video_metadata = videos_df.loc[videos_df['youtube_id'] == video['id'], ['duration_seconds', 'duration_minutes', 'duration_hours', 'encountered_home', 'encountered_search', 'encountered_recommend', 'encountered_all']]\n",
    "\n",
    "        return {\n",
    "            'youtube_id': video['id'],\n",
    "            'published_at': video['snippet']['publishedAt'],\n",
    "            'title': video['snippet']['title'],\n",
    "            'description': video['snippet']['description'],\n",
    "            'channel_id': video['snippet']['channelId'],\n",
    "            'language': video['snippet']['defaultAudioLanguage'] if 'defaultAudioLanguage' in video['snippet'] else np.nan,\n",
    "            'duration_seconds': video_metadata['duration_seconds'].values[0],\n",
    "            'duration_minutes': video_metadata['duration_minutes'].values[0],\n",
    "            'duration_hours': video_metadata['duration_hours'].values[0],\n",
    "            'view_count': video['statistics']['viewCount'] if 'viewCount' in video['statistics'] else np.nan,\n",
    "            'like_count': video['statistics']['likeCount'] if 'likeCount' in video['statistics'] else np.nan,\n",
    "            'dislike_count': video['statistics']['dislikeCount'] if 'dislikeCount' in video['statistics'] else np.nan,\n",
    "            'favorite_count': video['statistics']['favoriteCount'] if 'favoriteCount' in video['statistics'] else np.nan,\n",
    "            'comment_count': video['statistics']['commentCount'] if 'commentCount' in video['statistics'] else np.nan,\n",
    "            'encountered_home': video_metadata['encountered_home'].values[0],\n",
    "            'encountered_search': video_metadata['encountered_search'].values[0],\n",
    "            'encountered_recommend': video_metadata['encountered_recommend'].values[0],\n",
    "            'encountered_all': video_metadata['encountered_all'].values[0],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_encountered_videos = []\n",
    "\n",
    "for video_id in youtube_ids:\n",
    "    path = f'{VIDEO_BASE_DIR}/{video_id}/{video_id}.json'\n",
    "    if os.path.exists(path):\n",
    "        processed_video = process_encountered_video_metadata(path, videos)\n",
    "        processed_encountered_videos.append(processed_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_encountered_videos_df = pd.DataFrame(processed_encountered_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_encountered_videos_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_encountered_videos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_encountered_videos_df.to_csv('../Data/normalized_data/videos_metadata_processed.csv', index=False, quoting=csv.QUOTE_ALL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57e8ab2c44c7cc3097d31685c867aa29b59a70c4aee7409180d9015f3b8ee2df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
